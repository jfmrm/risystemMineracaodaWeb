<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>[1802.02277] From Game-theoretic Multi-agent Log Linear Learning to Reinforcement
  Learning</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="/css/arXiv.css?v=20170424" />
<meta name="citation_title" content="From Game-theoretic Multi-agent Log Linear Learning to Reinforcement Learning" />
<meta name="citation_author" content="Hasanbeig, Mohammadhosein" />
<meta name="citation_author" content="Pavel, Lacra" />
<meta name="citation_date" content="2018/02/07" />
<meta name="citation_online_date" content="2018/09/18" />
<meta name="citation_pdf_url" content="http://arxiv.org/pdf/1802.02277" />
<meta name="citation_arxiv_id" content="1802.02277" />
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>

<!-- Piwik -->
<script type="text/javascript">
var _paq = _paq || [];
_paq.push(["setDomains", ["*.arxiv.org"]]);
_paq.push(['trackPageView']);
_paq.push(['enableLinkTracking']);
(function()
{ var u="//webanalytics.library.cornell.edu/"; _paq.push(['setTrackerUrl', u+'piwik.php']); _paq.push(['setSiteId', 538]); var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s); }
)();
</script>
<!-- End Piwik Code -->


</head>
<body class="with-cu-identity">

<noscript><img src="//webanalytics.library.cornell.edu/piwik.php?idsite=538&rec=1" style="border:0;" alt="" /></noscript>

<div id="cu-identity">
<div id="cu-logo">
<a id="insignia-link" href="http://www.cornell.edu/"><img src="/icons/cu/cul_signature_unstyled.gif" alt="Cornell University" width="283" height="76" border="0" /></a>
<div id="unit-signature-links">
<a id="cornell-link" href="http://www.cornell.edu/">Cornell University</a>
<a id="unit-link" href="http://www.library.cornell.edu/">Library</a>
</div>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br />the Simons Foundation<br /> and member institutions</a>
</div>
</div>
<div id="header">
<h1><a href="/">arXiv.org</a> &gt; <a href="/list/cs/recent">cs</a> &gt; arXiv:1802.02277</h1>
<div id="search">
<form id="search-arxiv" method="GET" action="/search">
                
<div class="wrapper-search-arxiv">
<input class="keyword-field" type="text" name="query" placeholder="Search or Article ID"/>

<div class="filter-field">
<select name="searchtype">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="author">Author(s)</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option></select>
</div>
<input class="btn-search-arxiv" value="" type="submit">
<div class="links">(<a href="/help">Help</a> | <a href="/search/advanced">Advanced search</a>)</div>
</div>
<input type="hidden" name="source" value="header">
</form>
</div>
</div>
<div id="content">

<!--
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
    <rdf:Description
        rdf:about="http://arxiv.org/abs/1802.02277"
        dc:identifier="http://arxiv.org/abs/1802.02277"
        dc:title="From Game-theoretic Multi-agent Log Linear Learning to Reinforcement
  Learning"
        trackback:ping="http://arxiv.org/trackback/1802.02277" />
    </rdf:RDF>
-->

<div id="abs">
<div class="extra-services">

<div class="full-text">
<span class="descriptor">Full-text links:</span>
<h2>Download:</h2>
<ul>
<li><a href="/pdf/1802.02277" accesskey="f">PDF</a></li>
<li><a href="/format/1802.02277">Other formats</a></li>
</ul>
<div class="abs-license">(<a href="http://arxiv.org/licenses/nonexclusive-distrib/1.0/" title="Rights to this article">license</a>)</div>
</div><!--end full-text-->

<div class="browse">
<h3>Current browse context:</h3>
<div class="current">cs.LG</div>
<div class="prevnext"><span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1802.02277&amp;context=cs.LG&amp;function=prev" accesskey="p" title="previous in cs.LG (accesskey p)">&lt;&nbsp;prev</a></span>&nbsp;|&nbsp;<span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1802.02277&amp;context=cs.LG&amp;function=next" accesskey="n" title="next in cs.LG (accesskey n)">next&nbsp;&gt;</a></span>
<br /></div>
<div class="list"><a href="/list/cs.LG/new">new</a>&nbsp;| <a href="/list/cs.LG/recent">recent</a>&nbsp;| <a href="/list/cs.LG/1802">1802</a></div><h3>Change to browse by:</h3><div class="switch">
<a href="/abs/1802.02277?context=cs">cs</a><br />
<span class="subclass"><a href="/abs/1802.02277?context=cs.MA">cs.MA</a></span>
</div>

</div>
<div class="extra-ref-cite">
<h3>References &amp; Citations</h3><ul><li><a href="http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1802.02277">NASA ADS</a></li>
</ul>

</div>
<div class="dblp">
<h3><a href="http://www.informatik.uni-trier.de/~ley/db/">DBLP</a> - CS Bibliography</h3><div class="list">
<a href="http://www.informatik.uni-trier.de/~ley/db/journals/corr/corr1802.html#abs-1802-02277" title="listing on DBLP">listing</a> | <a href="http://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1802-02277" title="DBLP bibtex record">bibtex</a>
</div>
<div class="list">
<a href="http://dblp.uni-trier.de/search/author?author=Mohammadhosein%20Hasanbeig" title="DBLP author search">Mohammadhosein Hasanbeig</a><br />
<a href="http://dblp.uni-trier.de/search/author?author=Lacra%20Pavel" title="DBLP author search">Lacra Pavel</a><br />
</div>

</div>
<div class="bookmarks">
<div class="what-is-this">
<h3>Bookmark</h3> (<a href="/help/social_bookmarking">what is this?</a>)
</div>
<a href="/ct?url=http%3A%2F%2Fwww.citeulike.org%2Fposturl%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277%26title%3DFrom%2520Game-theoretic%2520Multi-agent%2520Log%2520Linear%2520Learning%2520to%2520Reinforcement%250A%2520%2520Learning%26authors%3D&amp;v=ab87d688" title="Bookmark on CiteULike"><img src="//static.arxiv.org/icons/social/citeulike.png" alt="CiteULike logo" /></a>
<a href="/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277%26description%3DFrom%2520Game-theoretic%2520Multi-agent%2520Log%2520Linear%2520Learning%2520to%2520Reinforcement%250A%2520%2520Learning&amp;v=835a42fa" title="Bookmark on BibSonomy"><img src="//static.arxiv.org/icons/social/bibsonomy.png" alt="BibSonomy logo" /></a>
<a href="/ct?url=https%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277&amp;v=eebf87b0" title="Bookmark on Mendeley"><img src="//static.arxiv.org/icons/social/mendeley.png" alt="Mendeley logo" /></a>
<a href="/ct?url=https%3A%2F%2Fdel.icio.us%2Fpost%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277%26description%3DFrom%2520Game-theoretic%2520Multi-agent%2520Log%2520Linear%2520Learning%2520to%2520Reinforcement%250A%2520%2520Learning&amp;v=674771e4" title="Bookmark on del.icio.us"><img src="//static.arxiv.org/icons/social/delicious.png" alt="del.icio.us logo" /></a>
<a href="/ct?url=https%3A%2F%2Fdigg.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277%26title%3DFrom%2520Game-theoretic%2520Multi-agent%2520Log%2520Linear%2520Learning%2520to%2520Reinforcement%250A%2520%2520Learning&amp;v=421e00f1" title="Bookmark on Digg"><img src="//static.arxiv.org/icons/social/digg.png" alt="Digg logo" /></a>
<a href="/ct?url=https%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277%26title%3DFrom%2520Game-theoretic%2520Multi-agent%2520Log%2520Linear%2520Learning%2520to%2520Reinforcement%250A%2520%2520Learning&amp;v=116de0ca" title="Bookmark on Reddit"><img src="//static.arxiv.org/icons/social/reddit.png" alt="Reddit logo" /></a>
<a href="/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1802.02277&amp;v=bdf1a9a5" title="Bookmark on ScienceWISE"><img src="//static.arxiv.org/icons/social/sciencewise.png" alt="ScienceWISE logo" /></a>

</div>
</div><!--end extra-services-->

<div class="leftcolumn">
<div class="subheader">
<h1>Computer Science > Machine Learning</h1>
</div>
<h1 class="title mathjax"><span class="descriptor">Title:</span>
From Game-theoretic Multi-agent Log Linear Learning to Reinforcement  Learning</h1>
<div class="authors"><span class="descriptor">Authors:</span>
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+M">Mohammadhosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+L">Lacra Pavel</a></div>
<div class="dateline">(Submitted on 7 Feb 2018 (<a href="/abs/1802.02277v1">v1</a>), last revised 18 Sep 2018 (this version, v2))</div>
<blockquote class="abstract mathjax">
<span class="descriptor">Abstract:</span> The main focus of this paper is on enhancement of two types of game-theoretic
learning algorithms: log-linear learning and reinforcement learning. The
standard analysis of log-linear learning needs a highly structured environment,
i.e. strong assumptions about the game from an implementation perspective. In
this paper, we introduce a variant of log-linear learning that provides
asymptotic guarantees while relaxing the structural assumptions to include
synchronous updates and limitations in information available to the players. On
the other hand, model-free reinforcement learning is able to perform even under
weaker assumptions on players' knowledge about the environment and other
players' strategies. We propose a reinforcement algorithm that uses a
double-aggregation scheme in order to deepen players' insight about the
environment and constant learning step-size which achieves a higher convergence
rate. Numerical experiments are conducted to verify each algorithm's robustness
and performance.
</blockquote>
<!--CONTEXT-->
<div class="metatable">
<table summary="Additional metadata">
<tr>
<td class="tablecell label">Subjects:
</td>
<td class="tablecell subjects"><span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)</td>
</tr>
<tr>
<td class="tablecell label">
Cite&nbsp;as:
</td>
<td class="tablecell arxivid"><a href="/abs/1802.02277">arXiv:1802.02277</a> [cs.LG]</td>
</tr>
<tr>
<td class="tablecell label">&nbsp;</td>
<td class="tablecell arxividv">(or <span class="arxivid"><a href="/abs/1802.02277v2">arXiv:1802.02277v2</a> [cs.LG]</span> for this version)</td>
</tr>
</table>
</div>
<div class="submission-history">
<h2>Submission history</h2>
From: Mohammadhosein Hasanbeig [<a href="https://arxiv.org/show-email/aa45c2d8/1802.02277">view email</a>]
<br />
<b><a href="/abs/1802.02277v1">[v1]</a></b> Wed, 7 Feb 2018 01:22:13 GMT  (919kb,D)<br />
<b>[v2]</b> Tue, 18 Sep 2018 15:10:20 GMT  (1568kb,D)<br />
</div>
<div class="endorsers"><a href="http://arxiv.org/auth/show-endorsers/1802.02277">Which authors of this paper are endorsers?</a> | <a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax/">What is MathJax?</a>)</div><script type="text/javascript" language="javascript">mathjaxToggle();</script>
</div><!--end leftcolumn-->
</div><!--end abs-->
</div>
<div id="footer">
<div class="footer-text">
<p>Link back to: <a href="http://arxiv.org/">arXiv</a>, <a href="/form">form interface</a>, <a href="/help/contact">contact</a>.</p>
</div>
<div class="social"><a href="https://twitter.com/arxiv"><img src="//static.arxiv.org/icons/twitter_logo_blue.png" alt="Twitter" title="Follow arXiv on Twitter"></a></div>
</div>
</body>
</html>
