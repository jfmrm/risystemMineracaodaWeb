<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>[1809.06625] SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="/css/arXiv.css?v=20170424" />
<meta name="citation_title" content="SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions" />
<meta name="citation_author" content="Zhang, Chengwei" />
<meta name="citation_author" content="Li, Xiaohong" />
<meta name="citation_author" content="Hao, Jianye" />
<meta name="citation_author" content="Chen, Siqi" />
<meta name="citation_author" content="Tuyls, Karl" />
<meta name="citation_author" content="Feng, Zhiyong" />
<meta name="citation_author" content="Xue, Wanli" />
<meta name="citation_author" content="Chen, Rong" />
<meta name="citation_date" content="2018/09/18" />
<meta name="citation_online_date" content="2018/09/18" />
<meta name="citation_pdf_url" content="http://arxiv.org/pdf/1809.06625" />
<meta name="citation_arxiv_id" content="1809.06625" />
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>

<!-- Piwik -->
<script type="text/javascript">
var _paq = _paq || [];
_paq.push(["setDomains", ["*.arxiv.org"]]);
_paq.push(['trackPageView']);
_paq.push(['enableLinkTracking']);
(function()
{ var u="//webanalytics.library.cornell.edu/"; _paq.push(['setTrackerUrl', u+'piwik.php']); _paq.push(['setSiteId', 538]); var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s); }
)();
</script>
<!-- End Piwik Code -->


</head>
<body class="with-cu-identity">

<noscript><img src="//webanalytics.library.cornell.edu/piwik.php?idsite=538&rec=1" style="border:0;" alt="" /></noscript>

<div id="cu-identity">
<div id="cu-logo">
<a id="insignia-link" href="http://www.cornell.edu/"><img src="/icons/cu/cul_signature_unstyled.gif" alt="Cornell University" width="283" height="76" border="0" /></a>
<div id="unit-signature-links">
<a id="cornell-link" href="http://www.cornell.edu/">Cornell University</a>
<a id="unit-link" href="http://www.library.cornell.edu/">Library</a>
</div>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br />the Simons Foundation<br /> and member institutions</a>
</div>
</div>
<div id="header">
<h1><a href="/">arXiv.org</a> &gt; <a href="/list/cs/recent">cs</a> &gt; arXiv:1809.06625</h1>
<div id="search">
<form id="search-arxiv" method="GET" action="/search">
                
<div class="wrapper-search-arxiv">
<input class="keyword-field" type="text" name="query" placeholder="Search or Article ID"/>

<div class="filter-field">
<select name="searchtype">
<option value="all">All fields</option>
<option value="title">Title</option>
<option value="author">Author(s)</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option></select>
</div>
<input class="btn-search-arxiv" value="" type="submit">
<div class="links">(<a href="/help">Help</a> | <a href="/search/advanced">Advanced search</a>)</div>
</div>
<input type="hidden" name="source" value="header">
</form>
</div>
</div>
<div id="content">

<!--
<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
         xmlns:dc="http://purl.org/dc/elements/1.1/"
         xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
    <rdf:Description
        rdf:about="http://arxiv.org/abs/1809.06625"
        dc:identifier="http://arxiv.org/abs/1809.06625"
        dc:title="SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions"
        trackback:ping="http://arxiv.org/trackback/1809.06625" />
    </rdf:RDF>
-->

<div id="abs">
<div class="extra-services">

<div class="full-text">
<span class="descriptor">Full-text links:</span>
<h2>Download:</h2>
<ul>
<li><a href="/pdf/1809.06625" accesskey="f">PDF</a></li>
<li><a href="/format/1809.06625">Other formats</a></li>
</ul>
<div class="abs-license">(<a href="http://arxiv.org/licenses/nonexclusive-distrib/1.0/" title="Rights to this article">license</a>)</div>
</div><!--end full-text-->

<div class="browse">
<h3>Current browse context:</h3>
<div class="current">cs.AI</div>
<div class="prevnext"><span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1809.06625&amp;context=cs.AI&amp;function=prev" accesskey="p" title="previous in cs.AI (accesskey p)">&lt;&nbsp;prev</a></span>&nbsp;|&nbsp;<span class="arrow"><a href="http://arxiv.org/prevnext?site=arxiv.org&amp;id=1809.06625&amp;context=cs.AI&amp;function=next" accesskey="n" title="next in cs.AI (accesskey n)">next&nbsp;&gt;</a></span>
<br /></div>
<div class="list"><a href="/list/cs.AI/new">new</a>&nbsp;| <a href="/list/cs.AI/recent">recent</a>&nbsp;| <a href="/list/cs.AI/1809">1809</a></div><h3>Change to browse by:</h3><div class="switch">
<a href="/abs/1809.06625?context=cs">cs</a>
</div>

</div>
<div class="extra-ref-cite">
<h3>References &amp; Citations</h3><ul><li><a href="http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1809.06625">NASA ADS</a></li>
</ul>

</div>
<div class="bookmarks">
<div class="what-is-this">
<h3>Bookmark</h3> (<a href="/help/social_bookmarking">what is this?</a>)
</div>
<a href="/ct?url=http%3A%2F%2Fwww.citeulike.org%2Fposturl%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625%26title%3DSCC-rFMQ%2520Learning%2520in%2520Cooperative%2520Markov%2520Games%2520with%2520Continuous%2520Actions%26authors%3D&amp;v=1d258093" title="Bookmark on CiteULike"><img src="//static.arxiv.org/icons/social/citeulike.png" alt="CiteULike logo" /></a>
<a href="/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625%26description%3DSCC-rFMQ%2520Learning%2520in%2520Cooperative%2520Markov%2520Games%2520with%2520Continuous%2520Actions&amp;v=65232ccc" title="Bookmark on BibSonomy"><img src="//static.arxiv.org/icons/social/bibsonomy.png" alt="BibSonomy logo" /></a>
<a href="/ct?url=https%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625&amp;v=b5e4eec7" title="Bookmark on Mendeley"><img src="//static.arxiv.org/icons/social/mendeley.png" alt="Mendeley logo" /></a>
<a href="/ct?url=https%3A%2F%2Fdel.icio.us%2Fpost%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625%26description%3DSCC-rFMQ%2520Learning%2520in%2520Cooperative%2520Markov%2520Games%2520with%2520Continuous%2520Actions&amp;v=190cba93" title="Bookmark on del.icio.us"><img src="//static.arxiv.org/icons/social/delicious.png" alt="del.icio.us logo" /></a>
<a href="/ct?url=https%3A%2F%2Fdigg.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625%26title%3DSCC-rFMQ%2520Learning%2520in%2520Cooperative%2520Markov%2520Games%2520with%2520Continuous%2520Actions&amp;v=91d89a42" title="Bookmark on Digg"><img src="//static.arxiv.org/icons/social/digg.png" alt="Digg logo" /></a>
<a href="/ct?url=https%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625%26title%3DSCC-rFMQ%2520Learning%2520in%2520Cooperative%2520Markov%2520Games%2520with%2520Continuous%2520Actions&amp;v=d9dd1af1" title="Bookmark on Reddit"><img src="//static.arxiv.org/icons/social/reddit.png" alt="Reddit logo" /></a>
<a href="/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1809.06625&amp;v=726cd006" title="Bookmark on ScienceWISE"><img src="//static.arxiv.org/icons/social/sciencewise.png" alt="ScienceWISE logo" /></a>

</div>
</div><!--end extra-services-->

<div class="leftcolumn">
<div class="subheader">
<h1>Computer Science > Artificial Intelligence</h1>
</div>
<h1 class="title mathjax"><span class="descriptor">Title:</span>
SCC-rFMQ Learning in Cooperative Markov Games with Continuous Actions</h1>
<div class="authors"><span class="descriptor">Authors:</span>
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tuyls%2C+K">Karl Tuyls</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wanli Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rong Chen</a></div>
<div class="dateline">(Submitted on 18 Sep 2018)</div>
<blockquote class="abstract mathjax">
<span class="descriptor">Abstract:</span> Although many reinforcement learning methods have been proposed for learning
the optimal solutions in single-agent continuous-action domains, multiagent
coordination domains with continuous actions have received relatively few
investigations. In this paper, we propose an independent learner hierarchical
method, named Sample Continuous Coordination with recursive Frequency Maximum
Q-Value (SCC-rFMQ), which divides the cooperative problem with continuous
actions into two layers. The first layer samples a finite set of actions from
the continuous action spaces by a re-sampling mechanism with variable
exploratory rates, and the second layer evaluates the actions in the sampled
action set and updates the policy using a reinforcement learning cooperative
method. By constructing cooperative mechanisms at both levels, SCC-rFMQ can
handle cooperative problems in continuous action cooperative Markov games
effectively. The effectiveness of SCC-rFMQ is experimentally demonstrated on
two well-designed games, i.e., a continuous version of the climbing game and a
cooperative version of the boat problem. Experimental results show that
SCC-rFMQ outperforms other reinforcement learning algorithms.
</blockquote>
<!--CONTEXT-->
<div class="metatable">
<table summary="Additional metadata">
<tr>
<td class="tablecell label">Subjects:
</td>
<td class="tablecell subjects"><span class="primary-subject">Artificial Intelligence (cs.AI)</span></td>
</tr>
<tr>
<td class="tablecell label">
Cite&nbsp;as:
</td>
<td class="tablecell arxivid"><a href="/abs/1809.06625">arXiv:1809.06625</a> [cs.AI]</td>
</tr>
<tr>
<td class="tablecell label">&nbsp;</td>
<td class="tablecell arxividv">(or <span class="arxivid"><a href="/abs/1809.06625v1">arXiv:1809.06625v1</a> [cs.AI]</span> for this version)</td>
</tr>
</table>
</div>
<div class="submission-history">
<h2>Submission history</h2>
From: Chengwei Zhang [<a href="https://arxiv.org/show-email/19f39ac5/1809.06625">view email</a>]
<br />
<b>[v1]</b> Tue, 18 Sep 2018 10:19:35 GMT  (433kb,D)<br />
</div>
<div class="endorsers"><a href="http://arxiv.org/auth/show-endorsers/1809.06625">Which authors of this paper are endorsers?</a> | <a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax/">What is MathJax?</a>)</div><script type="text/javascript" language="javascript">mathjaxToggle();</script>
</div><!--end leftcolumn-->
</div><!--end abs-->
</div>
<div id="footer">
<div class="footer-text">
<p>Link back to: <a href="http://arxiv.org/">arXiv</a>, <a href="/form">form interface</a>, <a href="/help/contact">contact</a>.</p>
</div>
<div class="social"><a href="https://twitter.com/arxiv"><img src="//static.arxiv.org/icons/twitter_logo_blue.png" alt="Twitter" title="Follow arXiv on Twitter"></a></div>
</div>
</body>
</html>
